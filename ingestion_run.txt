(AI_Doc_assistant) PS C:\Davinder\Udemy\LangChain-AIAgents-EdenMarco>  c:; cd 'c:\Davinder\Udemy\LangChain-AIAgents-EdenMarco'; & 'c:\Davinder\Udemy\LangChain-AIAgents-EdenMarco\LangchainProjects\AI_Doc_assistant\.venv\Scripts\python.exe' 'c:\Users\dpvir\.vscode\extensions\ms-python.debugpy-2025.10.0-win32-x64\bundled\libs\debugpy\launcher' '53591' '--' 'C:\Davinder\Udemy\LangChain-AIAgents-EdenMarco\LangchainProjects\AI_Doc_assistant\ingestion.py' 
c:\Davinder\Udemy\LangChain-AIAgents-EdenMarco\LangchainProjects\AI_Doc_assistant\.venv\Lib\site-packages\langchain_pinecone\__init__.py:3: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.

For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`
with: `from pydantic import BaseModel`
or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet.  from pydantic.v1 import BaseModel

  from langchain_pinecone.vectorstores import Pinecone, PineconeVectorStore

============================================================
ðŸš€ Starting Document Ingestion and Indexing Process
============================================================

â„¹ï¸  Loading documents from LangChain documentation website...
â„¹ï¸  Using Tavily batch processing for crawling and extracting web pages
âœ… Site map created with 20 pages to extract
â„¹ï¸  Processing 4 chunks of URLs for extraction

============================================================
ðŸš€ Starting asynchronous extraction of text from URL batches
============================================================

â„¹ï¸  Processing batch num: 1
â„¹ï¸  Processing batch num: 2
â„¹ï¸  Processing batch num: 3
â„¹ï¸  Processing batch num: 4
âœ… Extracted text from 5 URLs in batch 3
âœ… Extracted text from 5 URLs in batch 1
âœ… Extracted text from 4 URLs in batch 2
âœ… Extracted text from 4 URLs in batch 4
âœ… Successfully extracted text from 18 URLs with 0 failed batches
âœ… Extracted text from 18 URLs from LangChain documentation website

============================================================
ðŸš€ Splitting documents into smaller chunks for embedding
============================================================

âœ… Split into 89 chunks of text from 18 documents

============================================================
ðŸš€ Starting asynchronous indexing of documents to vector store
============================================================

â„¹ï¸  Total documents to index: 89
â„¹ï¸  Created 1 batches for indexing
â„¹ï¸  Indexing batch 1 with 89 documents
âœ… Successfully indexed batch 1
âœ… All batches indexed successfully.
âœ… Completed indexing all documents.

============================================================
ðŸš€ INDEXING PIPELINE COMPLETED SUCCESSFULLY
============================================================

â„¹ï¸  SUMMARY:
â„¹ï¸   URLs mapped: 20
â„¹ï¸   Documents extracted: 18
â„¹ï¸   Text chunks created: 89
â„¹ï¸   Vector store: Pinecone - langchain-doc-index
(AI_Doc_assistant) PS C:\Davinder\Udemy\LangChain-AIAgents-EdenMarco> 